---
name: rag_implementation
router_kit: AIKit
description: RAG (Retrieval Augmented Generation) kod seviyesinde uygulama, LangChain ve LlamaIndex pratikleri.
metadata:
  skillport:
    category: ai
    tags: [ai, algorithms, artificial intelligence, automation, chatbots, cognitive services, deep learning, embeddings, frameworks, generative ai, inference, large language models, llm, llama-index, langchain, machine learning, model fine-tuning, natural language processing, neural networks, nlp, openai, prompt engineering, rag, rag implementation_1, retrieval augmented generation, workflow automation]      - agents
---

# ğŸ¤– RAG Implementation

> Retrieval Augmented Generation (RAG) sistemlerini kod seviyesinde inÅŸa etme rehberi.

---

## ğŸ› ï¸ Frameworks

### LangChain
Composable bileÅŸenlerle zincir (Chain) oluÅŸturma.
```python
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI

qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(),
    retriever=vector_db.as_retriever()
)
```

### LlamaIndex
Veri odaklÄ± (Data connectors) RAG kurulumu.
```python
from llama_index import VectorStoreIndex, SimpleDirectoryReader

documents = SimpleDirectoryReader('data/').load_data()
index = VectorStoreIndex.from_documents(documents)
engine = index.as_query_engine()
```

---

## ğŸ“¦ Key Steps

### 1. Documents Loading & Chunking
```python
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=100
)
chunks = text_splitter.split_documents(docs)
```

### 2. Embeddings & Store
VektÃ¶rleÅŸtirme ve veritabanÄ±na kayÄ±t.

### 3. Retrieval & Prompting
Soruyla ilgili parÃ§alarÄ± Ã§ekme ve prompt'a enjekte etme.

---

## ğŸ”§ Workflow

> **Kaynak:** [LangChain Documentation](https://python.langchain.com/docs/get_started/introduction) & [LlamaIndex Documentation](https://docs.llamaindex.ai/en/stable/)

### AÅŸama 1: Setup & Data Ingestion
- [ ] **Loaders**: `PyPDFLoader`, `DirectoryLoader` veya custom API loader'larÄ± ile veriyi topla.
- [ ] **Metadata**: Chunk'lara kaynak linki, sayfa numarasÄ± veya tarih gibi metadata'larÄ± ekle (Source citing iÃ§in).
- [ ] **Syncing**: Kaynak veri deÄŸiÅŸtiÄŸinde vektÃ¶r DB'nin nasÄ±l gÃ¼ncelleneceÄŸini (Incremental sync) planla.

### AÅŸama 2: Indexing & Storage
- [ ] **Splitting**: Verinin anlamÄ±nÄ± bozmadan bÃ¶l (Semantic splitting dene).
- [ ] **Vectorization**: `text-embedding-3-small` (OpenAI) gibi maliyet/performans dengeli bir model kullan.
- [ ] **Vector DB**: `Chroma`, `Pinecone` veya `pgvector` kurulumunu yap ve index'le.

### AÅŸama 3: Query & QA
- [ ] **Retriever**: `Top-k` parametresini ve search tipini (Similarity, MMR) optimize et.
- [ ] **Prompt Template**: Modele "Verilen baÄŸlam dÄ±ÅŸÄ±nda cevap verme" gibi katÄ± kurallar iÃ§eren sistem promptu yaz.
- [ ] **Validation**: Cevap iÃ§ine dÃ¶kÃ¼man kaynaklarÄ±nÄ± (Citations) ekleyerek ÅŸeffaflÄ±ÄŸÄ± saÄŸla.

### Kontrol NoktalarÄ±
| AÅŸama | DoÄŸrulama |
|-------|-----------|
| 1 | Chunk overlap deÄŸeri baÄŸlam kaybÄ±nÄ± Ã¶nlÃ¼yor mu? |
| 2 | VektÃ¶r DB rate limitlerine takÄ±lÄ±yor mu? |
| 3 | "I don't know" yanÄ±tÄ±, veri bulunamadÄ±ÄŸÄ±nda tetikleniyor mu? |

---

*RAG Implementation v1.1 - Enhanced*
